{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Incident Root Cause Analysis \n",
    "\n",
    "Incident Reports in ITOps usually states the symptoms. Identifying the root cause of the symptom quickly is a key determinant to reducing resolution times and improving user satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/itops\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "    - scikit-learn\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/osx-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/osx-64::absl-py-0.9.0-py37_0\n",
      "  astor              pkgs/main/osx-64::astor-0.8.0-py37_0\n",
      "  blas               pkgs/main/osx-64::blas-1.0-mkl\n",
      "  c-ares             pkgs/main/osx-64::c-ares-1.15.0-h1de35cc_1001\n",
      "  gast               pkgs/main/osx-64::gast-0.2.2-py37_0\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-py_0\n",
      "  grpcio             pkgs/main/osx-64::grpcio-1.16.1-py37h044775b_1\n",
      "  h5py               pkgs/main/osx-64::h5py-2.10.0-py37h3134771_0\n",
      "  hdf5               pkgs/main/osx-64::hdf5-1.10.4-hfa1e0ec_0\n",
      "  intel-openmp       pkgs/main/osx-64::intel-openmp-2019.4-233\n",
      "  joblib             pkgs/main/noarch::joblib-0.15.1-py_0\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  libgfortran        pkgs/main/osx-64::libgfortran-3.0.1-h93005f0_2\n",
      "  libprotobuf        pkgs/main/osx-64::libprotobuf-3.11.4-hd9629dc_0\n",
      "  llvm-openmp        pkgs/main/osx-64::llvm-openmp-10.0.0-h28b9765_0\n",
      "  markdown           pkgs/main/osx-64::markdown-3.1.1-py37_0\n",
      "  mkl                pkgs/main/osx-64::mkl-2019.4-233\n",
      "  mkl-service        pkgs/main/osx-64::mkl-service-2.3.0-py37hfbe908c_0\n",
      "  mkl_fft            pkgs/main/osx-64::mkl_fft-1.0.15-py37h5e564d8_0\n",
      "  mkl_random         pkgs/main/osx-64::mkl_random-1.1.1-py37h959d312_0\n",
      "  numpy              pkgs/main/osx-64::numpy-1.18.1-py37h7241aed_0\n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.18.1-py37h3304bdc_1\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
      "  pandas             pkgs/main/osx-64::pandas-1.0.3-py37h6c726b0_0\n",
      "  protobuf           pkgs/main/osx-64::protobuf-3.11.4-py37h0a44026_0\n",
      "  pytz               pkgs/main/noarch::pytz-2020.1-py_0\n",
      "  scikit-learn       pkgs/main/osx-64::scikit-learn-0.22.1-py37h27c97d8_0\n",
      "  scipy              pkgs/main/osx-64::scipy-1.4.1-py37h9fa6033_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.0.0-pyhb38c66f_1\n",
      "  tensorflow         pkgs/main/osx-64::tensorflow-2.0.0-mkl_py37hda344b4_0\n",
      "  tensorflow-base    pkgs/main/osx-64::tensorflow-base-2.0.0-mkl_py37h66b1bf0_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.0.0-pyh2649769_0\n",
      "  termcolor          pkgs/main/osx-64::termcolor-1.1.0-py37_1\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0\n",
      "  wrapt              pkgs/main/osx-64::wrapt-1.12.1-py37h1de35cc_1\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#Install all related packages. If you find additional packages missing, please follow the same technique.\n",
    "#If you are not using anaconda, then use pip to install the same packages\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.04. Preprocessing Incident Data\n",
    "\n",
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID              int64\n",
      "CPU_LOAD        int64\n",
      "MEMORY_LOAD     int64\n",
      "DELAY           int64\n",
      "ERROR_1000      int64\n",
      "ERROR_1001      int64\n",
      "ERROR_1002      int64\n",
      "ERROR_1003      int64\n",
      "ROOT_CAUSE     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CPU_LOAD</th>\n",
       "      <th>MEMORY_LOAD</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>ERROR_1000</th>\n",
       "      <th>ERROR_1001</th>\n",
       "      <th>ERROR_1002</th>\n",
       "      <th>ERROR_1003</th>\n",
       "      <th>ROOT_CAUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NETWORK_DELAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CPU_LOAD  MEMORY_LOAD  DELAY  ERROR_1000  ERROR_1001  ERROR_1002  \\\n",
       "0   1         0            0      0           0           1           0   \n",
       "1   2         0            0      0           0           0           0   \n",
       "2   3         0            1      1           0           0           1   \n",
       "3   4         0            1      0           1           1           0   \n",
       "4   5         1            1      0           1           0           1   \n",
       "\n",
       "   ERROR_1003     ROOT_CAUSE  \n",
       "0           1         MEMORY  \n",
       "1           1         MEMORY  \n",
       "2           1         MEMORY  \n",
       "3           1         MEMORY  \n",
       "4           0  NETWORK_DELAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load the data file into a Pandas Dataframe\n",
    "symptom_data = pd.read_csv(\"root_cause_analysis.csv\")\n",
    "\n",
    "#Explore the data loaded\n",
    "print(symptom_data.dtypes)\n",
    "symptom_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert  data\n",
    "\n",
    "Input data needs to be converted to formats that can be consumed by ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature variables : (1000, 7)\n",
      "Shape of target variable : (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "symptom_data['ROOT_CAUSE'] = label_encoder.fit_transform(\n",
    "                                symptom_data['ROOT_CAUSE'])\n",
    "\n",
    "#Convert Pandas DataFrame to a numpy vector\n",
    "np_symptom = symptom_data.to_numpy().astype(float)\n",
    "\n",
    "#Extract the feature variables (X)\n",
    "X_train = np_symptom[:,1:8]\n",
    "\n",
    "#Extract the target variable (Y), convert to one-hot-encoding\n",
    "Y_train=np_symptom[:,8]\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train,3)\n",
    "\n",
    "print(\"Shape of feature variables :\", X_train.shape)\n",
    "print(\"Shape of target variable :\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.05. Building the Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 1.0220 - accuracy: 0.5962 - val_loss: 0.9374 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.8533 - accuracy: 0.7975 - val_loss: 0.7940 - val_accuracy: 0.7600\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.6964 - accuracy: 0.8062 - val_loss: 0.6707 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.5683 - accuracy: 0.8125 - val_loss: 0.5842 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.4944 - accuracy: 0.8125 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.4536 - accuracy: 0.8363 - val_loss: 0.5364 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.4380 - accuracy: 0.8375 - val_loss: 0.5246 - val_accuracy: 0.8100\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.4271 - accuracy: 0.8475 - val_loss: 0.5230 - val_accuracy: 0.8100\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.4202 - accuracy: 0.8438 - val_loss: 0.5210 - val_accuracy: 0.8100\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.4150 - accuracy: 0.8487 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 0.4089 - accuracy: 0.8525 - val_loss: 0.5136 - val_accuracy: 0.7900\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.4047 - accuracy: 0.8475 - val_loss: 0.5062 - val_accuracy: 0.7900\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3988 - accuracy: 0.8562 - val_loss: 0.5167 - val_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.3940 - accuracy: 0.8637 - val_loss: 0.5057 - val_accuracy: 0.7900\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.3899 - accuracy: 0.8550 - val_loss: 0.5021 - val_accuracy: 0.8100\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3845 - accuracy: 0.8537 - val_loss: 0.5002 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3817 - accuracy: 0.8625 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 0.3787 - accuracy: 0.8587 - val_loss: 0.5002 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 0.3736 - accuracy: 0.8600 - val_loss: 0.4911 - val_accuracy: 0.7900\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3692 - accuracy: 0.8612 - val_loss: 0.4929 - val_accuracy: 0.8000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense-Layer-1 (Dense)        (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "Dense-Layer-2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Final (Dense)                (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 17,923\n",
      "Trainable params: 17,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Setup Training Parameters\n",
    "EPOCHS=20\n",
    "BATCH_SIZE=100\n",
    "VERBOSE=1\n",
    "OUTPUT_CLASSES=len(label_encoder.classes_)\n",
    "N_HIDDEN=128\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "#Create a Keras sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "#Add a Dense Layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(7,),\n",
    "                              name='Dense-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a second dense layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Dense-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a softmax layer for categorial prediction\n",
    "model.add(keras.layers.Dense(OUTPUT_CLASSES,\n",
    "                             name='Final',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#Compile the model, using Adam optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Build the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.06. Predicting Root Causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATABASE_ISSUE']\n"
     ]
    }
   ],
   "source": [
    "#Pass individual flags to Predict the root cause\n",
    "CPU_LOAD=1\n",
    "MEMORY_LOAD=0\n",
    "DELAY=0\n",
    "ERROR_1000=0\n",
    "ERROR_1001=1\n",
    "ERROR_1002=1\n",
    "ERROR_1003=0\n",
    "\n",
    "prediction=model.predict_classes(\n",
    "    [[CPU_LOAD,MEMORY_LOAD,DELAY,\n",
    "      ERROR_1000,ERROR_1001,ERROR_1002,ERROR_1003]])\n",
    "\n",
    "print(label_encoder.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATABASE_ISSUE' 'NETWORK_DELAY' 'MEMORY' 'DATABASE_ISSUE'\n",
      " 'DATABASE_ISSUE']\n"
     ]
    }
   ],
   "source": [
    "#Predicting as a Batch\n",
    "print(label_encoder.inverse_transform(\n",
    "        model.predict_classes([[1,0,0,0,1,1,0],\n",
    "                                [0,1,1,1,0,0,0],\n",
    "                                [1,1,0,1,1,0,1],\n",
    "                                [0,0,0,0,0,1,0],\n",
    "                                [1,0,1,0,1,1,1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
